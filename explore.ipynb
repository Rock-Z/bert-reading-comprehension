{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCMN Explore Notebook\n",
    "\n",
    "## Step 1: Load data and see what our problems are like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from data import read_examples\n",
    "\n",
    "data_path = './RACE/'\n",
    "train_high, train_middle = read_examples(os.path.join(data_path, 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: \n",
      " high1000.txt\n",
      "passage: \n",
      " When newspapers and radio describe the damage caused by a hurricane  named Hazel, girls named Hazel are probably teased  by their friends. To keep out of trouble, the Weather Bureau says,\"Any _ between hurricane names and the names of particular girls is purely accidental.\"\n",
      "Some women became angry because hurricanes are given their names, but many other women are proud to see their names make headlines. They don't even care that they are the names of destructive storms. Because more women seem to like it than dislike it, the Weather Bureau has decided to continue using girl's names for hurricanes.\n",
      "In some ways a hurricane is like a person. After it is born, it grows and develops, then becomes old and dies. Each hurricane has a character of its own. Each follows its own path through the world, and people remember it long after it gone. So it is natural to give hurricanes' names, and to talk about them almost if they were alive.\n",
      "questions: \n",
      " ['What happens to girls named Hazel according to the passage?', 'Public opinions make the Weather Bureau   _  .']\n",
      "options: \n",
      " [['They suffer from hurricanes.', 'The Weather Bureau look for them.', 'Others often make fun of them.', \"They can't find boyfriend.\"], ['consider the disagreement of some women', 'go on naming hurricanes after women', 'name hurricanes after men', 'look for a new method to name hurricanes']]\n",
      "answers: \n",
      " ['C', 'B']\n"
     ]
    }
   ],
   "source": [
    "from utils import print_example\n",
    "\n",
    "print_example(train_high, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Getting a BERT layer and its corresponding preprocessor\n",
    "We found bert-base to be too big for our hardware, so two smaller bert instances are tried. Among those the 2-layer-128-hidden one also only has a `max-seq-length` of 128, instead of the original 512. Considering the length of our passages a larger small model is used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "arguments = dict(seq_length=512)\n",
    "\n",
    "#preprocess = hub.load('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
    "preprocess = hub.load('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
    "bert_preprocess = hub.KerasLayer(preprocess)\n",
    "\n",
    "#bert = hub.load('https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1')\n",
    "bert = hub.load('https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/2')\n",
    "bert_layer = hub.KerasLayer(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import dcmn_preprocess\n",
    "\n",
    "sample_size = 1000\n",
    "sample_data = train_high[:1000]\n",
    "validation_data = train_high[sample_size:sample_size + 100]\n",
    "\n",
    "sample_inputs, sample_answers = dcmn_preprocess(sample_data)\n",
    "valid_inputs, valid_answers = dcmn_preprocess(validation_data)\n",
    "answer_dict = {'A': tf.constant([1, 0, 0, 0]),\n",
    "               'B': tf.constant([0, 1, 0, 0]),\n",
    "               'C': tf.constant([0, 0, 1, 0]),\n",
    "               'D': tf.constant([0, 0, 0, 1])}\n",
    "sample_answers_encoded = tf.convert_to_tensor([answer_dict[a] for a in sample_answers])\n",
    "valid_answers_encoded = tf.convert_to_tensor([answer_dict[a] for a in valid_answers])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model and training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from model import DCMN, GateLayers\n",
    "\n",
    "config = {'n_choices': 4,\n",
    "          'hidden_size': 256, #Under current setup, must adjust to match bert embedding size\n",
    "          'dropout': 0.1,\n",
    "          'bert_preprocess': bert_preprocess,\n",
    "          'bert': bert_layer,\n",
    "          'gate_layer': GateLayers,\n",
    "          'classifier': Dense(4, activation='softmax')}\n",
    "\n",
    "model = DCMN(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "325/325 [==============================] - 69s 193ms/step - loss: 1.7241 - categorical_accuracy: 0.2510 - val_loss: 1.4667 - val_categorical_accuracy: 0.3059\n",
      "Epoch 2/5\n",
      "325/325 [==============================] - 63s 194ms/step - loss: 1.6140 - categorical_accuracy: 0.2818 - val_loss: 1.5714 - val_categorical_accuracy: 0.2895\n",
      "Epoch 3/5\n",
      "325/325 [==============================] - 62s 191ms/step - loss: 1.6178 - categorical_accuracy: 0.2932 - val_loss: 1.5602 - val_categorical_accuracy: 0.2982\n",
      "Epoch 4/5\n",
      "325/325 [==============================] - 63s 193ms/step - loss: 1.6365 - categorical_accuracy: 0.3068 - val_loss: 1.4048 - val_categorical_accuracy: 0.3478\n",
      "Epoch 5/5\n",
      "325/325 [==============================] - 64s 198ms/step - loss: 1.5418 - categorical_accuracy: 0.3090 - val_loss: 1.3041 - val_categorical_accuracy: 0.3932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e3d00addf0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(5e-3),\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics = [tf.keras.metrics.CategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "model.fit(x = sample_inputs, y = sample_answers_encoded, batch_size = 10, epochs = 5, validation_data=(valid_inputs, valid_answers_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "325/325 [==============================] - 64s 195ms/step - loss: 1.4691 - categorical_accuracy: 0.3361 - val_loss: 1.4420 - val_categorical_accuracy: 0.3771\n",
      "Epoch 2/10\n",
      "325/325 [==============================] - 64s 196ms/step - loss: 1.4840 - categorical_accuracy: 0.3315 - val_loss: 1.4612 - val_categorical_accuracy: 0.3605\n",
      "Epoch 3/10\n",
      "325/325 [==============================] - 62s 192ms/step - loss: 1.4710 - categorical_accuracy: 0.3447 - val_loss: 1.6720 - val_categorical_accuracy: 0.3534\n",
      "Epoch 4/10\n",
      "325/325 [==============================] - 61s 189ms/step - loss: 1.5667 - categorical_accuracy: 0.3358 - val_loss: 1.3973 - val_categorical_accuracy: 0.4049\n",
      "Epoch 5/10\n",
      "325/325 [==============================] - 64s 196ms/step - loss: 1.5294 - categorical_accuracy: 0.3549 - val_loss: 1.3826 - val_categorical_accuracy: 0.3938\n",
      "Epoch 6/10\n",
      "325/325 [==============================] - 62s 191ms/step - loss: 1.5824 - categorical_accuracy: 0.3410 - val_loss: 1.3140 - val_categorical_accuracy: 0.4083\n",
      "Epoch 7/10\n",
      "325/325 [==============================] - 61s 189ms/step - loss: 1.5050 - categorical_accuracy: 0.3558 - val_loss: 1.2849 - val_categorical_accuracy: 0.4277\n",
      "Epoch 8/10\n",
      "325/325 [==============================] - 61s 189ms/step - loss: 1.4801 - categorical_accuracy: 0.3592 - val_loss: 1.3625 - val_categorical_accuracy: 0.3987\n",
      "Epoch 9/10\n",
      "325/325 [==============================] - 61s 188ms/step - loss: 1.4737 - categorical_accuracy: 0.3768 - val_loss: 1.3550 - val_categorical_accuracy: 0.4166\n",
      "Epoch 10/10\n",
      "325/325 [==============================] - 61s 188ms/step - loss: 1.4505 - categorical_accuracy: 0.3814 - val_loss: 1.3009 - val_categorical_accuracy: 0.4311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e3e6c973d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = sample_inputs, y = sample_answers_encoded, batch_size = 10, epochs = 10, validation_data=(valid_inputs, valid_answers_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "325/325 [==============================] - 63s 193ms/step - loss: 1.5176 - categorical_accuracy: 0.3626 - val_loss: 1.2669 - val_categorical_accuracy: 0.4425\n",
      "Epoch 2/20\n",
      "325/325 [==============================] - 61s 189ms/step - loss: 1.4682 - categorical_accuracy: 0.3682 - val_loss: 1.3286 - val_categorical_accuracy: 0.4289\n",
      "Epoch 3/20\n",
      "325/325 [==============================] - 61s 189ms/step - loss: 1.4560 - categorical_accuracy: 0.3910 - val_loss: 1.1997 - val_categorical_accuracy: 0.4678\n",
      "Epoch 4/20\n",
      "325/325 [==============================] - 62s 191ms/step - loss: 1.4656 - categorical_accuracy: 0.3885 - val_loss: 1.6048 - val_categorical_accuracy: 0.3549\n",
      "Epoch 5/20\n",
      "325/325 [==============================] - 63s 193ms/step - loss: 1.4793 - categorical_accuracy: 0.3679 - val_loss: 1.3531 - val_categorical_accuracy: 0.4258\n",
      "Epoch 6/20\n",
      "325/325 [==============================] - 62s 191ms/step - loss: 1.3939 - categorical_accuracy: 0.4012 - val_loss: 1.3491 - val_categorical_accuracy: 0.4440\n",
      "Epoch 7/20\n",
      "325/325 [==============================] - 62s 190ms/step - loss: 1.4027 - categorical_accuracy: 0.4027 - val_loss: 1.3426 - val_categorical_accuracy: 0.4277\n",
      "Epoch 8/20\n",
      "325/325 [==============================] - 62s 190ms/step - loss: 1.4326 - categorical_accuracy: 0.3938 - val_loss: 1.3897 - val_categorical_accuracy: 0.4298\n",
      "Epoch 9/20\n",
      "325/325 [==============================] - 62s 190ms/step - loss: 1.4522 - categorical_accuracy: 0.4018 - val_loss: 1.2099 - val_categorical_accuracy: 0.4712\n",
      "Epoch 10/20\n",
      "325/325 [==============================] - 62s 190ms/step - loss: 1.4065 - categorical_accuracy: 0.4002 - val_loss: 1.3773 - val_categorical_accuracy: 0.4043\n",
      "Epoch 11/20\n",
      "325/325 [==============================] - 62s 190ms/step - loss: 1.4272 - categorical_accuracy: 0.4036 - val_loss: 1.2110 - val_categorical_accuracy: 0.4755\n",
      "Epoch 12/20\n",
      "325/325 [==============================] - 61s 189ms/step - loss: 1.4161 - categorical_accuracy: 0.4135 - val_loss: 1.2595 - val_categorical_accuracy: 0.4601\n",
      "Epoch 13/20\n",
      "325/325 [==============================] - 62s 190ms/step - loss: 1.4263 - categorical_accuracy: 0.4197 - val_loss: 1.1965 - val_categorical_accuracy: 0.4773\n",
      "Epoch 14/20\n",
      "325/325 [==============================] - 63s 194ms/step - loss: 1.4300 - categorical_accuracy: 0.4194 - val_loss: 1.3976 - val_categorical_accuracy: 0.4280\n",
      "Epoch 15/20\n",
      "325/325 [==============================] - 62s 191ms/step - loss: 1.3979 - categorical_accuracy: 0.4200 - val_loss: 1.1503 - val_categorical_accuracy: 0.5020\n",
      "Epoch 16/20\n",
      "325/325 [==============================] - 63s 193ms/step - loss: 1.3670 - categorical_accuracy: 0.4280 - val_loss: 1.2846 - val_categorical_accuracy: 0.4730\n",
      "Epoch 17/20\n",
      "325/325 [==============================] - 60s 185ms/step - loss: 1.3436 - categorical_accuracy: 0.4397 - val_loss: 1.1548 - val_categorical_accuracy: 0.4980\n",
      "Epoch 18/20\n",
      "325/325 [==============================] - 60s 184ms/step - loss: 1.3123 - categorical_accuracy: 0.4607 - val_loss: 1.1035 - val_categorical_accuracy: 0.5298\n",
      "Epoch 19/20\n",
      "325/325 [==============================] - 60s 185ms/step - loss: 1.3986 - categorical_accuracy: 0.4342 - val_loss: 1.1093 - val_categorical_accuracy: 0.5344\n",
      "Epoch 20/20\n",
      "325/325 [==============================] - 60s 185ms/step - loss: 1.4231 - categorical_accuracy: 0.4265 - val_loss: 1.2103 - val_categorical_accuracy: 0.4718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e3e6c9bb20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = sample_inputs, y = sample_answers_encoded, batch_size = 10, epochs = 20, validation_data=(valid_inputs, valid_answers_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "325/325 [==============================] - 60s 184ms/step - loss: 1.3414 - categorical_accuracy: 0.4564 - val_loss: 1.2453 - val_categorical_accuracy: 0.4820\n",
      "Epoch 2/20\n",
      "325/325 [==============================] - 59s 182ms/step - loss: 1.3399 - categorical_accuracy: 0.4533 - val_loss: 1.2465 - val_categorical_accuracy: 0.4915\n",
      "Epoch 3/20\n",
      "325/325 [==============================] - 60s 185ms/step - loss: 1.3688 - categorical_accuracy: 0.4342 - val_loss: 1.1547 - val_categorical_accuracy: 0.5088\n",
      "Epoch 4/20\n",
      "325/325 [==============================] - 59s 181ms/step - loss: 1.3388 - categorical_accuracy: 0.4453 - val_loss: 1.1918 - val_categorical_accuracy: 0.4968\n",
      "Epoch 5/20\n",
      "325/325 [==============================] - 59s 181ms/step - loss: 1.3468 - categorical_accuracy: 0.4576 - val_loss: 1.2611 - val_categorical_accuracy: 0.4727\n",
      "Epoch 6/20\n",
      "325/325 [==============================] - 59s 181ms/step - loss: 1.3794 - categorical_accuracy: 0.4419 - val_loss: 1.3383 - val_categorical_accuracy: 0.4934\n",
      "Epoch 7/20\n",
      "325/325 [==============================] - 58s 180ms/step - loss: 1.3603 - categorical_accuracy: 0.4656 - val_loss: 1.3245 - val_categorical_accuracy: 0.4440\n",
      "Epoch 8/20\n",
      "325/325 [==============================] - 59s 180ms/step - loss: 1.3188 - categorical_accuracy: 0.4659 - val_loss: 1.4376 - val_categorical_accuracy: 0.4342\n",
      "Epoch 9/20\n",
      "325/325 [==============================] - 59s 181ms/step - loss: 1.3451 - categorical_accuracy: 0.4493 - val_loss: 1.0383 - val_categorical_accuracy: 0.5680\n",
      "Epoch 10/20\n",
      "325/325 [==============================] - 59s 181ms/step - loss: 1.2508 - categorical_accuracy: 0.4749 - val_loss: 1.0694 - val_categorical_accuracy: 0.5495\n",
      "Epoch 11/20\n",
      "325/325 [==============================] - 59s 181ms/step - loss: 1.3297 - categorical_accuracy: 0.4681 - val_loss: 1.0784 - val_categorical_accuracy: 0.5387\n",
      "Epoch 12/20\n",
      "325/325 [==============================] - 59s 181ms/step - loss: 1.2827 - categorical_accuracy: 0.4869 - val_loss: 1.1701 - val_categorical_accuracy: 0.5143\n",
      "Epoch 13/20\n",
      "325/325 [==============================] - 59s 182ms/step - loss: 1.2124 - categorical_accuracy: 0.5060 - val_loss: 1.0127 - val_categorical_accuracy: 0.5763\n",
      "Epoch 14/20\n",
      "325/325 [==============================] - 59s 181ms/step - loss: 1.2474 - categorical_accuracy: 0.4915 - val_loss: 1.1575 - val_categorical_accuracy: 0.5270\n",
      "Epoch 15/20\n",
      "325/325 [==============================] - 59s 181ms/step - loss: 1.2589 - categorical_accuracy: 0.4891 - val_loss: 0.9989 - val_categorical_accuracy: 0.5825\n",
      "Epoch 16/20\n",
      "325/325 [==============================] - 59s 182ms/step - loss: 1.2520 - categorical_accuracy: 0.4974 - val_loss: 1.1154 - val_categorical_accuracy: 0.5430\n",
      "Epoch 17/20\n",
      "325/325 [==============================] - 60s 184ms/step - loss: 1.2377 - categorical_accuracy: 0.4998 - val_loss: 1.0742 - val_categorical_accuracy: 0.5618\n",
      "Epoch 18/20\n",
      "325/325 [==============================] - 59s 181ms/step - loss: 1.2070 - categorical_accuracy: 0.5017 - val_loss: 1.1647 - val_categorical_accuracy: 0.5304\n",
      "Epoch 19/20\n",
      "325/325 [==============================] - 59s 181ms/step - loss: 1.1931 - categorical_accuracy: 0.5162 - val_loss: 1.0489 - val_categorical_accuracy: 0.5566\n",
      "Epoch 20/20\n",
      "325/325 [==============================] - 59s 182ms/step - loss: 1.2719 - categorical_accuracy: 0.4986 - val_loss: 1.0651 - val_categorical_accuracy: 0.5637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e3e71b6fa0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = sample_inputs, y = sample_answers_encoded, batch_size = 10, epochs = 20, validation_data=(valid_inputs, valid_answers_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "325/325 [==============================] - 58s 177ms/step - loss: 1.1895 - categorical_accuracy: 0.5211 - val_loss: 1.4590 - val_categorical_accuracy: 0.4357\n",
      "Epoch 2/20\n",
      "325/325 [==============================] - 63s 194ms/step - loss: 1.2842 - categorical_accuracy: 0.5042 - val_loss: 1.2659 - val_categorical_accuracy: 0.4878\n",
      "Epoch 3/20\n",
      "325/325 [==============================] - 63s 194ms/step - loss: 1.2598 - categorical_accuracy: 0.4980 - val_loss: 1.1062 - val_categorical_accuracy: 0.5424\n",
      "Epoch 4/20\n",
      "325/325 [==============================] - 62s 192ms/step - loss: 1.2234 - categorical_accuracy: 0.5109 - val_loss: 1.5501 - val_categorical_accuracy: 0.4132\n",
      "Epoch 5/20\n",
      "325/325 [==============================] - 63s 193ms/step - loss: 1.2415 - categorical_accuracy: 0.5005 - val_loss: 1.0561 - val_categorical_accuracy: 0.5646\n",
      "Epoch 6/20\n",
      "325/325 [==============================] - 62s 191ms/step - loss: 1.1548 - categorical_accuracy: 0.5378 - val_loss: 1.3105 - val_categorical_accuracy: 0.4946\n",
      "Epoch 7/20\n",
      "325/325 [==============================] - 63s 195ms/step - loss: 1.2000 - categorical_accuracy: 0.5193 - val_loss: 1.0112 - val_categorical_accuracy: 0.5933\n",
      "Epoch 8/20\n",
      "325/325 [==============================] - 63s 195ms/step - loss: 1.1516 - categorical_accuracy: 0.5384 - val_loss: 1.0451 - val_categorical_accuracy: 0.5532\n",
      "Epoch 9/20\n",
      "325/325 [==============================] - 66s 205ms/step - loss: 1.1507 - categorical_accuracy: 0.5365 - val_loss: 1.3754 - val_categorical_accuracy: 0.4921\n",
      "Epoch 10/20\n",
      "325/325 [==============================] - 65s 199ms/step - loss: 1.1642 - categorical_accuracy: 0.5362 - val_loss: 0.9374 - val_categorical_accuracy: 0.6130\n",
      "Epoch 11/20\n",
      "325/325 [==============================] - 63s 194ms/step - loss: 1.1506 - categorical_accuracy: 0.5446 - val_loss: 1.0853 - val_categorical_accuracy: 0.5683\n",
      "Epoch 12/20\n",
      "325/325 [==============================] - 66s 202ms/step - loss: 1.1270 - categorical_accuracy: 0.5479 - val_loss: 1.0076 - val_categorical_accuracy: 0.5908\n",
      "Epoch 13/20\n",
      "325/325 [==============================] - 65s 201ms/step - loss: 1.0923 - categorical_accuracy: 0.5686 - val_loss: 0.8455 - val_categorical_accuracy: 0.6664\n",
      "Epoch 14/20\n",
      "325/325 [==============================] - 63s 193ms/step - loss: 1.1115 - categorical_accuracy: 0.5628 - val_loss: 0.9788 - val_categorical_accuracy: 0.6075\n",
      "Epoch 15/20\n",
      "325/325 [==============================] - 63s 193ms/step - loss: 1.0916 - categorical_accuracy: 0.5661 - val_loss: 0.9104 - val_categorical_accuracy: 0.6281\n",
      "Epoch 16/20\n",
      "325/325 [==============================] - 64s 197ms/step - loss: 1.0882 - categorical_accuracy: 0.5705 - val_loss: 0.9570 - val_categorical_accuracy: 0.6035\n",
      "Epoch 17/20\n",
      "325/325 [==============================] - 62s 191ms/step - loss: 1.0552 - categorical_accuracy: 0.5828 - val_loss: 0.9061 - val_categorical_accuracy: 0.6297\n",
      "Epoch 18/20\n",
      "325/325 [==============================] - 63s 194ms/step - loss: 1.1182 - categorical_accuracy: 0.5594 - val_loss: 0.9261 - val_categorical_accuracy: 0.6253\n",
      "Epoch 19/20\n",
      "325/325 [==============================] - 64s 197ms/step - loss: 1.0487 - categorical_accuracy: 0.5797 - val_loss: 1.0315 - val_categorical_accuracy: 0.5883\n",
      "Epoch 20/20\n",
      "325/325 [==============================] - 66s 203ms/step - loss: 1.0608 - categorical_accuracy: 0.5800 - val_loss: 0.9055 - val_categorical_accuracy: 0.6448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e40d8c6d00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = sample_inputs, y = sample_answers_encoded, batch_size = 10, epochs = 20, validation_data=(valid_inputs, valid_answers_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt_path = './trained_models/dcmn_bert_4_256_epoch_80/'\n",
    "model.save_weights(chkpt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0446042525ddf6dce139292a1bae01839848d5bfa885523a501a8716580c0d07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
