{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from data import read_examples\n",
    "\n",
    "data_path = './RACE/'\n",
    "train_high, train_middle = read_examples(os.path.join(data_path, 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: \n",
      " high1000.txt\n",
      "passage: \n",
      " When newspapers and radio describe the damage caused by a hurricane  named Hazel, girls named Hazel are probably teased  by their friends. To keep out of trouble, the Weather Bureau says,\"Any _ between hurricane names and the names of particular girls is purely accidental.\"\n",
      "Some women became angry because hurricanes are given their names, but many other women are proud to see their names make headlines. They don't even care that they are the names of destructive storms. Because more women seem to like it than dislike it, the Weather Bureau has decided to continue using girl's names for hurricanes.\n",
      "In some ways a hurricane is like a person. After it is born, it grows and develops, then becomes old and dies. Each hurricane has a character of its own. Each follows its own path through the world, and people remember it long after it gone. So it is natural to give hurricanes' names, and to talk about them almost if they were alive.\n",
      "questions: \n",
      " ['What happens to girls named Hazel according to the passage?', 'Public opinions make the Weather Bureau   _  .']\n",
      "options: \n",
      " [['They suffer from hurricanes.', 'The Weather Bureau look for them.', 'Others often make fun of them.', \"They can't find boyfriend.\"], ['consider the disagreement of some women', 'go on naming hurricanes after women', 'name hurricanes after men', 'look for a new method to name hurricanes']]\n",
      "answers: \n",
      " ['C', 'B']\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "\n",
    "print(\"id: \\n\", train_high[i].id)\n",
    "print(\"passage: \\n\",train_high[i].passage)\n",
    "print(\"questions: \\n\",train_high[i].question)\n",
    "print(\"options: \\n\",train_high[i].options)\n",
    "print(\"answers: \\n\",train_high[i].answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "arguments = dict(seq_length=512)\n",
    "\n",
    "#preprocess = hub.load('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
    "preprocess = hub.load('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
    "bert_preprocess = hub.KerasLayer(preprocess)\n",
    "\n",
    "#bert = hub.load('https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1')\n",
    "bert = hub.load('https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/2')\n",
    "bert_layer = hub.KerasLayer(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import dcmn_preprocess\n",
    "\n",
    "sample_size = 1000\n",
    "sample_data = train_high[:1000]\n",
    "validation_data = train_high[sample_size:sample_size + 100]\n",
    "\n",
    "sample_inputs, sample_answers = dcmn_preprocess(sample_data)\n",
    "valid_inputs, valid_answers = dcmn_preprocess(sample_data)\n",
    "answer_dict = {'A': tf.constant([1, 0, 0, 0]),\n",
    "               'B': tf.constant([0, 1, 0, 0]),\n",
    "               'C': tf.constant([0, 0, 1, 0]),\n",
    "               'D': tf.constant([0, 0, 0, 1])}\n",
    "sample_answers_encoded = tf.convert_to_tensor([answer_dict[a] for a in sample_answers])\n",
    "valid_answers_encoded = tf.convert_to_tensor([answer_dict[a] for a in valid_answers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from model import DCMN, GateLayers\n",
    "\n",
    "config = {'n_choices': 4,\n",
    "          'hidden_size': 256, #Under current setup, must adjust to match bert embedding size\n",
    "          'dropout': 0.1,\n",
    "          'bert_preprocess': bert_preprocess,\n",
    "          'bert': bert_layer,\n",
    "          'gate_layer': GateLayers,\n",
    "          'classifier': Dense(4, activation='softmax')}\n",
    "\n",
    "model = DCMN(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "325/325 [==============================] - 69s 193ms/step - loss: 1.7241 - categorical_accuracy: 0.2510 - val_loss: 1.4667 - val_categorical_accuracy: 0.3059\n",
      "Epoch 2/5\n",
      "325/325 [==============================] - 63s 194ms/step - loss: 1.6140 - categorical_accuracy: 0.2818 - val_loss: 1.5714 - val_categorical_accuracy: 0.2895\n",
      "Epoch 3/5\n",
      "325/325 [==============================] - 62s 191ms/step - loss: 1.6178 - categorical_accuracy: 0.2932 - val_loss: 1.5602 - val_categorical_accuracy: 0.2982\n",
      "Epoch 4/5\n",
      "325/325 [==============================] - 63s 193ms/step - loss: 1.6365 - categorical_accuracy: 0.3068 - val_loss: 1.4048 - val_categorical_accuracy: 0.3478\n",
      "Epoch 5/5\n",
      "325/325 [==============================] - 64s 198ms/step - loss: 1.5418 - categorical_accuracy: 0.3090 - val_loss: 1.3041 - val_categorical_accuracy: 0.3932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e3d00addf0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(5e-3),\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics = [tf.keras.metrics.CategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "model.fit(x = sample_inputs, y = sample_answers_encoded, batch_size = 10, epochs = 5, validation_data=(valid_inputs, valid_answers_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x = sample_inputs, y = sample_answers_encoded, batch_size = 10, epochs = 10, validation_data=(valid_inputs, valid_answers_encoded))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0446042525ddf6dce139292a1bae01839848d5bfa885523a501a8716580c0d07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
